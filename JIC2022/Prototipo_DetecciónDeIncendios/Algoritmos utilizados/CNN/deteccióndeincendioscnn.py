# -*- coding: utf-8 -*-
"""DetecciónDeIncendiosCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HizNNeUNXL67dECAZJQEPXO9P1AFQyUy

# Detección de huego y humo
"""

pip uninstall tensorflow

pip install tensorflow==2.1.0

import tensorflow as tf
print(tf.__version__)
print(tf.test.gpu_device_name())

#Importando Librerias Necesarios.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import SeparableConv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense

class FireDetectionNet:
	@staticmethod
	def build(width, height, depth, classes):
   
		model = Sequential()
		inputShape = (height, width, depth)
		chanDim = -1

		model.add(SeparableConv2D(16, (7, 7), padding="same",
			input_shape=inputShape))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))

		model.add(SeparableConv2D(32, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))

		model.add(SeparableConv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
	
		model.add(SeparableConv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))

		model.add(Flatten())
		model.add(Dense(128))
		model.add(Activation("relu"))
		model.add(BatchNormalization())
		model.add(Dropout(0.5))

		model.add(Dense(128))
		model.add(Activation("relu"))
		model.add(BatchNormalization())
		model.add(Dropout(0.5))

		model.add(Dense(classes))
		model.add(Activation("softmax"))

		#Devuelve la arquitectura de la red ya construida
		return model

"""# Montando Google Drive """

from google.colab import drive
drive.mount('/content/drive')

"""# Importando Data de Google Drive"""

# inicializa la ruta a los directorios de conjuntos de datos de fuego y no fuego
FIRE_PATH = '/content/drive/MyDrive/Fuego y Humo'
NON_FIRE_PATH = '/content/drive/MyDrive/Fuegon´t'

# inicializa las etiquetas de clase en el conjunto de datos
CLASSES = ["No Fuego", "Fuego"]

# definimos el tamaño de la división de entrenamiento y prueba
TRAIN_SPLIT = 0.81
TEST_SPLIT = 0.19

# definimos la tasa de aprendizaje inicial, el tamaño del lote y el número de épocas
INIT_LR = 1e-3
BATCH_SIZE = 32
NUM_EPOCHS = 50

# salida con etiquetas/anotaciones junto con el número de imágenes a:
SAMPLE_SIZE = 50

# importamos matplotlib para que las cifras se puedan guardar en segundo plano
import matplotlib
matplotlib.use("Agg")

# importamos librerias necesarias
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import argparse
import cv2
import sys

def load_dataset(datasetPath):
  # toma las rutas a todas las imágenes en nuestro directorio de conjuntos de datos, luego
  # inicializa nuestra listas de imágenes
	imagePaths = list(paths.list_images(datasetPath))
	data = []

  # recorrer las rutas de la imagen
	for imagePath in imagePaths:
    # cargar la imagen y cambiar su tamaño para que sea de 128x128 píxeles fijos,
    # ignorando la relación de aspecto
		image = cv2.imread(imagePath)
		image = cv2.resize(image, (128, 128))

		# añade la imagen a las listas de datos
		data.append(image)

	# devuelve la lista de datos como una matriz NumPy
	return np.array(data, dtype="float32")

# construimos el analizador de argumentos y analiza los argumentos

# carga las imágenes de fuego y no fuego
print("[INFO] Cargando data...")
fireData = load_dataset( FIRE_PATH)
nonFireData = load_dataset( NON_FIRE_PATH)
print("[INFO] Completo")

"""# Preprocesamiento y exploración del conjuntos de datos"""

print(fireData.shape)
print(nonFireData.shape)

# construimos las etiquetas para los datos
fireLabels = np.ones((fireData.shape[0],))
nonFireLabels = np.zeros((nonFireData.shape[0],))
# apila los datos de incendios con los datos que no son de incendios, luego escalar los datos
# al rango [0, 1]
data = np.vstack([fireData, nonFireData])
labels = np.hstack([fireLabels, nonFireLabels])

data /= 255
# realiza una codificación one-hot en las etiquetas y tiene en cuenta el sesgo en los
# datos etiquetados
labels = to_categorical(labels, num_classes=2)
classTotals = labels.sum(axis=0)
classWeight = classTotals.max() / classTotals

print(data.shape)
print(labels.shape)
print(labels[1:])
print(classTotals)

# construimos la división de entrenamiento y la de prueba
(trainX, testX, trainY, testY) = train_test_split(data, labels,
	test_size= TEST_SPLIT, random_state=42)

print(trainX.shape)
print(trainY.shape)
print(testX.shape)
print(testY.shape)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.figure()
plt.imshow(trainX[1])
plt.colorbar()
plt.grid(False)
plt.show()

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(trainX[i], cmap=plt.cm.binary)
    if trainY[i][0] == 1:
      plt.xlabel("No Fuego")
    else:
      plt.xlabel("Fuego")

plt.show()

"""# Modelo de Entrenamiento"""

from tensorflow import keras
from tensorflow.keras.callbacks import TensorBoard

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
!rm -rf ./logs/ # Elimina ejecuciones anteriores
# %tensorboard --logdir logs/
tensorboard = TensorBoard(log_dir="./logs", histogram_freq=1)
# inicializa aumento de datos de entrenamiento
aug = ImageDataGenerator(
	rotation_range=30,
	zoom_range=0.15,
	width_shift_range=0.2,
	height_shift_range=0.2,
	shear_range=0.15,
	horizontal_flip=True,
	fill_mode="nearest")

# inicializar el optimizador y el modelo
print("[INFO] compilando modelo...")
opt = keras.optimizers.Adam(lr=INIT_LR)
model = FireDetectionNet.build(width=128, height=128, depth=3,
	classes=2)
model.compile(loss="binary_crossentropy", optimizer=opt,
	metrics=["accuracy"])

# verifica si estamos tratando de encontrar una tasa de aprendizaje óptima
# antes de entrenar para el número completo de épocas

# entrenando la red
print("[INFO] Entrenando la Red...")
H = model.fit_generator(
	aug.flow(trainX, trainY, batch_size= BATCH_SIZE),
	validation_data=(testX, testY),
	steps_per_epoch=trainX.shape[0] //  BATCH_SIZE,
	epochs= NUM_EPOCHS,
	class_weight=classWeight,verbose=1, callbacks=[tensorboard])

# evalua la red y mostrar un informe de clasificación
print("[INFO] Evaluando la Red...")
predictions = model.predict(testX, batch_size= BATCH_SIZE)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names= CLASSES))

#  serializa el modelo al disco
#print("[INFO] serializing network to '{}'...".format( MODEL_PATH))
#model.save( MODEL_PATH)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
#import matplotlib.pyplot as plt
#print(H.history["loss"])
#N = np.arange(0,  NUM_EPOCHS)
#print(N)
#plt.plot(N,H.history["loss"])
import matplotlib.pyplot as plt
import numpy as np

N = np.arange(0,  NUM_EPOCHS)
plt.style.use("ggplot")
fig = plt.figure()
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.plot(N, H.history["accuracy"], label="train_acc")
plt.plot(N, H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")

fig.savefig('my_figure.png')

"""# Explorando Predicción"""

print(predictions.shape)
print(predictions[:1])

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(testX[i], cmap=plt.cm.binary)
    if testY[i][0] == 1:
      if predictions[i][0] > 0.5:
        plt.xlabel("No Fuego", color='green')
      else:
        plt.xlabel("No Fuego", color='red')
    else:
      if predictions[i][1] > 0.5:
        plt.xlabel("Fuego", color='green')
      else:
        plt.xlabel("Fuego", color='red')

plt.show()

MODEL_PATH = '/content/drive/My Drive/firedata'
model.save( MODEL_PATH)

model.summary()

"""# Guardando Modelo"""

# save model and architecture to single file
model.save("/content/drive/My Drive/Colab Notebooks/2017ee80.h5")
model.save_weights("/content/drive/My Drive/Colab Notebooks/pesos.h5")
print("Modelo guardado en Drive")

